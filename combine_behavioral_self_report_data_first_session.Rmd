---
title: "Power analysis"
output:
  html_document:
    df_print: paged
---


```{r}
Sys.setenv(R_CONFIG_ACTIVE = Sys.info()["nodename"])

#install.packages("tidystats")
library(stringr)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(rstatix)
library(data.table)
source("utils.R")
data_path <- "../../grant-writing-workshop/files/data/"

load(paste0(config::get("dev_analysis_data_dir"),"scored_data_w_demographics.RData"))
dropbox_file_dir = config::get("dev_analysis_data_dir")
scored<-scored_with_demographics
rm(scored_with_demographics)
scored$score <- as.numeric(scored$score)
scored$scale_name <- sub("-","_",scored$scale_name)
```

```{r}

#
scored %>% filter(scale_name %in% c("FCI")) %>% select(scored_scale) %>% unique

```
```{r}
scored$scale_name %>% unique
```


Now get BMI

```{r}
load(paste0(config::get("dev_analysis_data_dir"),"ppt_list_w_data.Rdata"))
#load("../../grant-writing-workshop/files/data/ppt_list_w_data_2022-08-17.Rdata")

ppt_list_w_data$date_0<-as.Date(ppt_list_w_data$date_0)
ppt_list_w_data$dob<-as.Date(ppt_list_w_data$dob)
ppt_list_w_data$age365<- round(as.numeric((ppt_list_w_data$date_0-ppt_list_w_data$dob)/365)*4,0)/4#rounding to nearest 0.25 to avoid identification

#our primary health outcome measure
ppt_health_outcomes <- ppt_list_w_data %>% select(dev_id,bf_1,weight_0,height_0,birthsex,age365,bmi_0,bmi_1) %>% filter(!is.na(bf_1))

ppt_health_outcomes$bmi <- ifelse(!is.na(ppt_health_outcomes$bmi_0),ppt_health_outcomes$bmi_0,ppt_health_outcomes$bmi_1)
rm(ppt_list_w_data)

#remove data of implausible bf_1 values
ppt_health_outcomes$bf_1[ppt_health_outcomes$bf_1<13]<-NA


#get a bf_1 score with sex regressed out
#do we want to regress out height as well???

#plot(ppt_health_outcomes$height_0,ppt_health_outcomes$bf_1)

#hmm that's fairly strong. 
#but does it hold after controlling for sex?
#I think it would be good to regress out height as well.
#so we will use a linear model to predict bf_1 from height and sex. 
cor.test(ppt_health_outcomes[birthsex==1, height_0],ppt_health_outcomes[birthsex==1,bf_1])
cor.test(ppt_health_outcomes[birthsex==2, height_0],ppt_health_outcomes[birthsex==2,bf_1])
#it does not.

#what about age?
cor.test(ppt_health_outcomes[birthsex==1, age365],ppt_health_outcomes[birthsex==1,bf_1])
cor.test(ppt_health_outcomes[birthsex==2, age365],ppt_health_outcomes[birthsex==2,bf_1])
#might be a moderate correlation within birth sex levels of age. so it is worth norming for age too
#if we were just controlling for a single variable we could z-score
#but now we're doing age as well.
#which would imply not z-scoring, we should use a linear model.

bf_model <- lm(bf_1~birthsex+age365, ppt_health_outcomes)
summary(bf_model)
#ppt_health_outcomes$bf_1_controlled <-NULL <- bf_model$residuals
ppt_health_outcomes$bf_1_controlled[as.numeric(rownames(bf_model$model))] <- bf_model$residuals

#simple model just zscoring within sex
#that allows for a more inuitive interpretation than errors from a linear model.
ppt_health_outcomes %<>% group_by(birthsex) %>% mutate(
  bf_1_bsexnormedzs = (bf_1-mean(bf_1,na.rm = TRUE))/sd(bf_1,na.rm = TRUE),
  
)


#cor.test(ppt_health_outcomes$birthsex,ppt_health_outcomes$bf_1)
plot(ppt_health_outcomes$birthsex,ppt_health_outcomes$bf_1)
#cor.test(ppt_health_outcomes$birthsex,ppt_health_outcomes$bf_1_bsexnormedzs)
#plot(ppt_health_outcomes$birthsex,ppt_health_outcomes$bf_1_bsexnormedzs)

#plot(ppt_health_outcomes$birthsex,ppt_health_outcomes$bf_1_controlled)

plot(ppt_health_outcomes$bf_1,ppt_health_outcomes$bf_1_controlled)




```


```{r}
min(ppt_health_outcomes$age365)

max(ppt_health_outcomes$age365)

table(ppt_health_outcomes$birthsex)
```



Now get behavioral measures.

```{r}

#sst_pes <- readr::read_csv("https://www.dropbox.com/s/vaubgp23y5j0m5g/post_error_slowing.csv?dl=0")
# sst_pes <- readr::read_csv(paste0("~/Dropbox (University of Oregon)/UO-SAN Lab/Berkman Lab/Devaluation/analysis_files/data/", "post_error_slowing.csv"))
sst_pes_simple <- readr::read_csv(paste0("~/Dropbox (University of Oregon)/UO-SAN Lab/Berkman Lab/Devaluation/analysis_files/data/", "post_error_slowing_simple_approach.csv"))
#should be wave 1 by default.
sst_data_1 <- readr::read_csv(file=paste0(dropbox_file_dir,"sst_summary_stats_by_run.csv"))
#the following file excluded becuase the subject IDs are probably labelled wrong.
#sst_data_2 <- readr::read_csv(file=paste0(dropbox_file_dir,"sst_pre_analyzed_stats.csv"))
sst_data_1_w1 <- sst_data_1%>%filter(runid==1 & waveid==1)%>% select(-runid, -waveid)
#sst_data_2_w1 <- sst_data_2 %>% filter(wave==1) %>% select(-wave)
sst_w1 <- sst_data_1_w1 %>%
  #merge(sst_data_1_w1,sst_data_2_w1,by.x ="subid",by.y="SubjectLabel",all = TRUE) %>%
  #merge(sst_pes[,2:ncol(sst_pes)],by="subid",all=TRUE) %>%
  merge(sst_pes_simple[,2:ncol(sst_pes_simple)],by="subid",all=TRUE)



roc_data <- readr::read_csv(file=paste0(dropbox_file_dir,"roc_summary_stats.csv"))
load(file=paste0(dropbox_file_dir,"wtp_summary_stats_across_runs.Rdata"))




#need to group across run
roc_data_across_runs<- roc_data %>% select(-run) %>% group_by(subjectID,wave) %>% summarise(across(everything(), mean))
roc_data_across_runs_w1 <- roc_data_across_runs %>%filter(wave==1)%>% select(-wave)

wtp_across_runs_wide <- wtp_across_runs %>% select(subject, value_level_mean, health_cond,wave) %>% group_by(subject,wave) %>% spread("health_cond","value_level_mean") %>% ungroup
wtp_across_runs_wide$unhealthy_minus_healthy <- wtp_across_runs_wide$unhealthy - wtp_across_runs_wide$healthy
wtp_across_runs_wide_w1 <- wtp_across_runs_wide%>%filter(wave==1) %>% select(-wave)
colnames(wtp_across_runs_wide_w1) <- paste0("WTP_",colnames(wtp_across_runs_wide_w1))



#sst_data$wave <- 1
colnames(sst_w1) <- paste0("SST_",colnames(sst_w1))
roc_data_across_runs_w1 <- rename(roc_data_across_runs_w1,c(subid=subjectID))
colnames(roc_data_across_runs_w1) <- paste0("ROC_",colnames(roc_data_across_runs_w1))
#roc_data_across_runs$runid <- as.double(stringr::str_match(roc_data_across_runs$run,"run(\\d)")[,2])

behavioral_data <- merge(sst_w1,roc_data_across_runs_w1,by.x=c("SST_subid"),by.y="ROC_subid",all = TRUE)
behavioral_data <- rename(behavioral_data,c(subid=SST_subid))
behavioral_data <- merge(behavioral_data,wtp_across_runs_wide_w1,by.x = "subid",by.y="WTP_subject",all=TRUE)



```





## Health measures include:


 - Percent Body Fat (`bf_1`)
 - BMI (`bmi_0`)
 
## Behavioral outcome measures

We also have behavioral outcome measures:

 - Food Frequency Questionnaire. Very closely related to the Food Craving Inventory so that needs to be considered carefully.
 


## Self-report predictor variables to investigate 

Which predictor scales should we include?
 
Need the behavioral and self-report imho
 
Before we decide which to include, perhaps we put them into categories: obvious theoretical link to outcome (3), possible theoretical link to outcome (2), no clear theoretical link to outcome (1).
 
Listing them by these categories we get:

### Obvious theoretical link to outcome

These are explicitly designed to measure constructs we are concerned about, like self control or habits.

 - Brief Self Control Scale
 - Self-reported Habit Index
 - Tempest Self-Regulation Questionnaire for Eating
 - Treatment Self-Regulation Questionnaire
 - Barratt Impulsiveness Scale
 - Eating Dysregulation Measure
 - Food Craving Inventory
 - Restraint Scale


### Possible theoretical link to outcome

These aren't explicitly designed to measure constructs we are concerned about, but there are theoretical reasons or at least 'stories you could tell' to expect a link to outcome.

 - Big Five
 - Planfulness
 - Regulatory Mode Questionnaire
 - Responses to Failure Scale
 - Perceived Competence Scale
 
 

### No clear theoretical link to outcome

For this category it is unclear why we would expect any link to the outcome (eating). Some are included in DEV more because of their theoretical link to the treatment rather than to baseline level of obesity.

 - Need for Cognition Scale
 - Vividness of Visual Imagery Questionnaire
 - Intrinsic Motivation Inventory
 - Adverse Childhood Experiences

### In DEV but not a construct of interest

These are in DEV but aren't psychological constructs and so I'm not considering them.

  - International Physical Activity Questionnaire
  - Demographic measures
  
## Behavioral predictor variables

 - WTP
    - price given for healthy foods
    - price given for unhealthy foods
    - difference between the above two
 - ROC
    - [regulate - look] craving reduction for healthy foods
    - [regulate - look] craving reduction for unhealthy foods
    - balance of the above two
 - SST
    - Participant behavioral net response bias toward healthy foods
    - Participant behavioral net response bias toward unhealthy foods
    - difference between the above
  

# Checking for presence of each of these  

Do we have these scales? let's take a look.

```{r}
table(scored$scale_name)
```


Group 1:

 - Brief Self Control Scale - Y
 - Self-reported Habit Index - N- no rubric
 - Tempest Self-Regulation Questionnaire for Eating - N- no rubric
 - Treatment Self-Regulation Questionnaire - N- no rubric
 - Barratt Impulsiveness Scale - N- no rubric
 - Eating Dysregulation Measure - Y
 - Food Craving Inventory - Y
 - Restraint Scale - N- no rubric


## the following were NOT pre-registered.
Group 2:

These aren't explicitly designed to measure constructs we are concerned about, but there are theoretical reasons or at least 'stories you could tell' to expect a link to outcome.

 - Big Five - Y
 - Planfulness -Y
 - Regulatory Mode Questionnaire - N- no rubric
 - Responses to Failure Scale - N- no rubric
 - Perceived Competence Scale - N- no rubric


<!-- ## scramble -->

<!-- ```{r} -->
<!-- #get a scrambled dataset we can use to test the pipeline without revealing any results -->
<!-- scored_dummy <- scored -->
<!-- scored_dummy$score <-sample(scored_dummy$score,length(scored_dummy$score)) -->
<!-- scored <- scored_dummy -->

<!-- ppt_health_outcomes$bmi_0<-sample(ppt_health_outcomes$bmi_0,nrow(ppt_health_outcomes)) -->
<!-- ppt_health_outcomes$bf_1<-sample(ppt_health_outcomes$bf_1,nrow(ppt_health_outcomes)) -->
<!-- ``` -->





## analysis (left over from previous analysis)

Get the first survey for each scale:

We have to change this method; and get EVERY survey for each scale....
```{r}
scored$survey_num <- as.numeric(str_trim(str_match(scored$survey_name,"[DEV Session \\s][\\d+][\\sSurveys]")))
first_survey_for_scale<-scored %>% group_by(scale_name) %>% dplyr::summarise("first_survey"=min(survey_num))

#then select it.
scored_fs <- scored %>%
  merge(first_survey_for_scale,by="scale_name") %>%
  filter(survey_num==first_survey)

print("survey used for each scale:")
print(first_survey_for_scale)


```





```{r}
sapply(unique(scored_fs$scale_name),function(sn){list(sn=unique(scored_fs[scored_fs$scale_name==sn,"scored_scale"]))})
```



### long-stage data cleaning


For some reason there's a lot of participants with missing RTFS data. Participants don't really miss any other scales but they o miss RTFS. Is that because it's the only scale not marked out with compulsory entry?



### test correlations, transform


```{r}


promote_minus_prevent <- get_promote_minus_prevent(scored_fs)


single_scale_values<-get_single_scale_predictors(scored_fs)

scales_wide<-merge(promote_minus_prevent,single_scale_values,by=c("SID","survey_name"),all=TRUE)

ppt_data_wide_raw_1 <- merge(scales_wide,ppt_health_outcomes,by.x="SID",by.y="dev_id",all=TRUE)

```

```{r}
scored_fs %>% filter(scale_name=="DEMO") %>% .$scored_scale %>% unique

scored_fs_demo_zscored <- scored_fs %>% filter(scale_name=="DEMO")
ses_grouped<-c("zipcode_median_income_acs", "household_income_per_person","household_income_level_medamount","education_own")

scored_fs_demo_zscored <- scored_fs_demo_zscored %>% data.frame %>% group_by(scored_scale) %>% 
  filter(scored_scale %in% ses_grouped) %>% 
  mutate(
  score_zscore=(score-mean(score,na.rm=TRUE))/sd(score,na.rm=TRUE),
  score_mean = mean(score,na.rm=TRUE),
  score_sd =sd(score,na.rm=TRUE)) %>% ungroup
#get a zscore of each

scored_fs_demo_zscored$score<- scored_fs_demo_zscored$score_zscore

scored_fs_demo_zscored_wide <- scored_fs_demo_zscored %>% 
  select(SID,survey_name,score,scored_scale) %>% tidyr::pivot_wider(names_from = scored_scale,values_from = score) %>%
  rowwise() %>%
  mutate(ses_aggregate=mean(c(education_own,zipcode_median_income_acs,household_income_per_person,household_income_level_medamount)))


```



```{r}
multi_scale_values<-get_multiscale_values(scored_fs)

ppt_data_wide_raw_2 <- merge(ppt_data_wide_raw_1,multi_scale_values,by=c("SID","survey_name"),all=TRUE)


ppt_data_wide <- merge(ppt_data_wide_raw_2,scored_fs_demo_zscored_wide,by=c("SID","survey_name"),all=TRUE)
```


```{r}
#grabs the FIRST score for each item per participant.
col_list <- lapply(colnames(ppt_data_wide %>% select(-survey_name,-SID)), function(col){
  return(ppt_data_wide %>% select(-survey_name) %>% .[,c("SID",col)] %>% filter(!is.na(.[col])) %>% group_by(SID) %>% summarise("{col}":=first(.data[[col]])))
})
data_by_ppt <- purrr::reduce(col_list, left_join,by="SID")



```


##Now get the behavioral data


```{r}
data_by_ppt <- merge(data_by_ppt,behavioral_data,by.x="SID",by.y="subid",all.x = TRUE,all.y=FALSE)

```

Now we do some contrasts we haven't done yet...

```{r}
data_by_ppt<-do_misc_self_report_summary_measures(data_by_ppt)
data_by_ppt <- do_aggregate_measures(data_by_ppt)
                                            
```



### get the modified FFQ

This is done here, rather than earlier, because it needs gender.


```{r}

#we need two things here:
#(1)  list of FFQ by individual item"
      #Can't use "scored"
      #need to use survey_long_clean from scorequaltrics_workflow. It's saved here:

load(paste0(dropbox_file_dir,"/raw_survey_data.RData"))
#(2)  list of birthsex. this is done easily enough with:
birthsex_key <- data_by_ppt[c("SID","birthsex_factor")]

#1=female, 2=male



# source("ffq_revision/get_ffq_v2.R")
# 
# ffq_v2_values <- score_ffqv2(surveys_long_clean,birthsex_key)
# colnames(ffq_v2_values) <- paste0("FFQ_v2_",colnames(ffq_v2_values))



```

```{r}

nutrient_density_scores <- readr::read_csv(paste0(
  config::get("nutrient_density_datapath"), "/Data files/DEV_NUTRIENT_DENSITY_PARTICIPANT.csv"))

score_cols <- setdiff(colnames(nutrient_density_scores),c("SID","survey_name"))

nutrient_density_scores$time_period <- stringr::str_match(nutrient_density_scores$survey_name,pattern = "DEV\\_(.*)\\_FFQ")[,2]
nds_wide <- nutrient_density_scores %>% 
  select(-survey_name)%>% 
  pivot_wider(names_from=time_period,values_from=score_cols,names_prefix = "FFQ_NutrientDensity_")

data_by_ppt<-merge(data_by_ppt,nds_wide,by="SID",all.x = TRUE,all.y=FALSE)

# data_by_ppt <- merge(data_by_ppt,ffq_v2_values,by.x="SID",by.y="FFQ_v2_SID",all.x = TRUE,all.y=FALSE)

```


Now we need to get the non-scale social values in here.

<!-- ```{r} -->
<!-- ppt_data_wide_dummy <- ppt_data_wide -->

<!-- for (cn in colnames(ppt_data_wide_dummy)[3:length(colnames(ppt_data_wide_dummy))]){ -->
<!--   print(cn) -->
<!--   ppt_data_wide_dummy[,cn]<-sample(ppt_data_wide_dummy[,cn],length(ppt_data_wide_dummy[,cn])) -->
<!-- } -->
<!-- rm(ppt_data_wide) -->
<!-- ``` -->


### wide-stage data cleaning

#### outlier removal

https://www.active.com/fitness/calculators/bodyfat

Classification	Women (% Fat)	Men (% Fat)
Essential Fat	10-12%	2-4%
Athletes	14-20%	6-13%
Fitness	21-24%	14-17%
Acceptable	25-31%	18-25%
Obese	32% +	25% +



With ~275 subjects, how often would we expect subjects 2 or 3 or 4 SD outside the mean?

First: what's the expected number of subjects we'd expect outside the mean:
```{r}
(1-pnorm(4,0,1))*275
(1-pnorm(5,0,1))*275

```

now what's the probability of finding subjects 4 or 5 SD outside the mean, on either side?


```{r}
(1-pnorm(3,0,1)^275)*2
(1-pnorm(4,0,1)^275)*2
(1-pnorm(5,0,1)^275)*2

```

Therefore I think it would be fair to exclude any data point more than 4 SD outside the mean. The odds of even one subject hitting above that mark are less than 1%, given a normal distribution.

```{r}

for (coln in colnames(data_by_ppt)[2:ncol(data_by_ppt)]){
  class(data_by_ppt[[coln]])
  if(sum(is.na(data_by_ppt[[coln]]))<length(data_by_ppt[[coln]])){
    
    na_row <- is.na(unlist(data_by_ppt[coln]))
    col_vals <- data_by_ppt[!na_row,coln]
    col_sids <- data_by_ppt[!na_row,"SID"]
    if(("factor" %in%class(col_vals))==FALSE){
      
      col_mean<-mean(col_vals)
      col_sd<-sd(col_vals)
      outliers_4sigma <- (col_vals < col_mean - col_sd * 4) | (col_vals > col_mean + col_sd * 4)
      outliers_5sigma <- (col_vals < col_mean - col_sd * 5) | (col_vals > col_mean + col_sd * 5)
      if(sum(outliers_4sigma)+sum(outliers_5sigma)>0){
        print(paste(coln, ": 4 sigma outliers are:",paste(col_sids[outliers_4sigma],collapse = ","), "; 5 sigma outliers are:",paste(data_by_ppt[outliers_5sigma,"SID"],collapse = ",")))
      }
      if(sum(outliers_4sigma)>0){
        print(paste0("removing ",as.character(sum(outliers_4sigma))," 4-sigma outliers from the ",coln, " column in the dataset."))
        for (outlier_sid in col_sids[outliers_4sigma]){
          print(outlier_sid)
          data_by_ppt[data_by_ppt$SID==outlier_sid,coln]<-NA
        }
      }
      
    }
  }
}

```

```{r}


# 
# 
# for (coln in colnames(data_by_ppt)[2:ncol(data_by_ppt)]){
#   print(coln)
#   class(data_by_ppt[[coln]])
#   if(sum(is.na(data_by_ppt[[coln]]))<length(data_by_ppt[[coln]])){
#     hist(unlist(data_by_ppt[coln]),breaks=20,main = coln)
#   }
#   
# }
```

```{r}
#remove implausible TRSQ score
data_by_ppt$TRSQ[data_by_ppt$TRSQ<5]<-NA
```



```{r}
readr::write_csv(data_by_ppt, file = paste0(dropbox_file_dir,"data_by_ppt.csv"))


```

