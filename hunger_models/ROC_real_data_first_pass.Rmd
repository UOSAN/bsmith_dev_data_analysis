---
title: "WTP Model first pass"
output: html_notebook
---

This is a first-pass attempt to model willingness to pay data. Let's put the code together, WITHOUT testing the data, then consider pre-registration and then a test.

What are we pre-registering? Something like:
 - health and liking scores predict payment scores significantly better than either choice alone
 - hunger ratings moderate liking, so that an interaction term can be observed between liking and hunger when predicting bid, indicating that liking is more important for predicting the bid score when participants are hungrier.
 - hunger ratings also moderate the influence of health, so that an interaction can be observed between liking and hunger when predicting bids so that when participants are hungrier liking is less important

To model these data, we'll use a multi-level model, where we predict individual bid based on health and liking score. At the participant level, we'll model hunger.

Do we model any other participant factors? These might include:

 - obesity level
 - demographics (sex/gender, age, income)
 - PSS

With only ~200 subjects, we're probably under-specified to test _interactions_ with more than a couple of participant-level variables.

Any other subject-level variables that might interact to predict greater predictivity of liking vs. health?

self control
 - impulsivity scale
 - self control scale
 - tempest self regulation scale for eating
 - restraint scale
 
food scarcity
  - childhood financial security
  - adult food security scale

reward sensitivity
 - Food Craving Inventory
 
Food habits
 - Food Frequency Inventory

Before testing each of these we may want to run some sort of correlation on them to look at the correlations between the scales. If items are uncorrelated, we could include them together in a single regression. If they are correlated, we might want to avoid testing them together, test their interaction, or pick one scale over another to analyze.

## original question

From our teams script the orignla question is

> We asked you to not eat for 3 hours prior to this appointment and to refrain from liquids for the past hour. Were you able to do that?  
> 
> And how hungry are you currently feeling on a scale from 1-5 where 1 = not hungry at all and 5 = extremely hungry? 
> 
> Record answer in Redcap 
> 
> Great! We would like you to continue fasting prior to the body composition assessment to obtain the most accurate results. After you complete the physical assessments, you’ll be able to drink fluids and after the MRI scan, we’ll provide you with a snack.  
> 
> We have a couple minutes before we need to get started. Would you like to visit the restroom or do you need anything before we get started? 
> 
> Do you have any questions for me before we start gathering some of the measurements? 

 

## Implementation

### First: group-level predictors

In linear modeling terms what we are looking for is a *varying slope*; the varying slope will have a *group-level predictor* (e.g., hunger).

See Gelman & Hill, 12.6: group-level predictors; also 13.1.

### Next: interaction of group-level predictor

this is discussed in 13.1

What we have isn't analogous to the simple radon problem, where we'res predicting indiviual-level (house) radon level from an individual-level predictor (floor=0 or 1) and a group-level (county) predictor. That would be analogous to predicting bid size based on hunger, food health, and food likeability separately. And I think, in a model, this would be using a group predictor to model the intercept of the individual level prediction.

Rather we want to get an interaction of the group-level predictor with the individual-level predictor. In the radon example, this would be like looking for an interaction between floor and county-level radon level.

In a multi-level model this isn't too complicated, right--it's just including the group-level item as a predictor of the group-level variable. This might be descrribed as predicting the slope $\beta_j$.

Gelman _still_ doesn't spell out the form for this in lme4 or lmer, though he does discuss it extensively. So. a quick google...

brief discussion here: https://biologyforfun.wordpress.com/2017/06/19/adding-group-level-predictors-in-glmm-using-lme4/ - not high quality and they specifically caution against using p-values ot test significance. Wonder if Gelman knows how to do it.

Gelman covers this in Section 17.2:  varying intercepts and slopes with group-level predictors. He only offers Bugs code, though. We might use stan.

Can try: https://cran.r-project.org/web/packages/equatiomatic/vignettes/lme4-lmer.html

See also: https://github.com/lme4/lme4/issues/473

hmmm...so, individual-level predictors are food healthiness and tastiness. we might add RT but let's keep it simple for now.


Let's get some data.


```{r}
Sys.setenv(R_CONFIG_ACTIVE = Sys.info()["nodename"])
data_dir <- config::get("dev_analysis_data_dir")
#hunger data
setwd(paste0(paste0(data_dir,"hunger/")))

source("DEV-Session1Data_R_2022-08-29_2358.r")
redcap_data<-data
rm(data)
```

```{r}
Sys.setenv(R_CONFIG_ACTIVE = Sys.info()["nodename"])
data_dir <- config::get("dev_analysis_data_dir")

library(readr)
#NEXT CHALLENGE: HOW TO GET LIKING RATINGS
#wtp data happens to have liking ratings in it, so we could load it right from there
#The next question for that though, is: how do we know what foods are being shown in the task?
#I'm not absolutely sure, the "stimulus" (crave, enutral, no crave) might make it redundant...
#but in any case, we could work in the specific food items by also importing the "stimulus key" files.
#this might be best done as an augment to the roc_behavioral_data_all script.
wtp_raw <- read_csv(paste0(data_dir,"wtp_behavdesign_clean.csv"))
roc_behavioral_data <- readr::read_csv(file = paste0(data_dir,"roc_behavioral_data_all.csv"))



```



```{r}
library(dplyr)
table(redcap_data$hunger_1)
session_1_redcap_data <-redcap_data %>% filter(grepl("session_1", redcap_event_name))
hunger_data <- session_1_redcap_data %>% select(dev_id,hunger_1)


regress_data<-merge(roc_behavioral_data,hunger_data,by.x="subjectID",by.y="dev_id",all.x = TRUE,all.y=FALSE)
```

Now let's adapt the columns to normed columns with hte names we used in the synthetic dtaset.


```{r}
#clean the rating column
#regress_data$rating_int<-as.integer(str_extract(regress_data$rating,"\\d*"))
#regress_data<-regress_data[1:1000,]
#regress_data[regress_data$response=="NULL","response"] <- NA
#regress_data$response<-as.numeric(regress_data$response)
#regress_data <- regress_data%>% group_by(subject,run,wave) %>% mutate(min_rating=min(rating_int,na.rm=TRUE),max_rating=max(rating_int,na.rm=TRUE)) %>% ungroup()
#regress_data$response_range <- regress_data$max_response - regress_data$min_response
#stopifnot(max(regress_data$response_range)==3)#max of the max range should be 3 exactly, the range from the max response minus the min response
#there are two groups of responses here grouped by run
#some use range 1,2,3,4; others use range 5,6,7,8
#we need to combine those for value.
#value_adjustment <- 0 - 4*(regress_data$min_response>4)
#regress_data$value_level <- regress_data$response + value_adjustment
#regress_data$value <- factor(regress_data$value_level,levels = c(1,2,3,4),labels="$0.00","$0.50","$1.00","$1.50")
#regress_data[regress_data$liking_rating==0,"liking_rating"]<-NA
```


```{r}

#must have tried for half an hour to et this to work within the loop and it didn't...
standardize<-function(x){return((x-mean(x,na.rm=TRUE))/sd(x,na.rm=TRUE))}

regress_data$rating_i<-as.integer(regress_data$rating)

regress_data$rating_norm<-standardize(regress_data$rating_i)

#regress_data$stimulus_f <- standardize(regress_data$liking_rating)

regress_data$hunger_norm <- standardize(regress_data$hunger_1)

regress_data$stimulus_f<-factor(regress_data$stimulus,levels=c("No Crave","Neutral","Crave"))

regress_data <- regress_data %>% group_by(subjectID,file,wave,run) %>% 
  mutate(trial_n=1:n())


```

```{r}
library(lme4)
#compared to "No Crave", Neutral and Craved stimuli were rated much more highly.
#don't really undersatnd why thre is no substantial differnce between Neutral and Crave foods
model <- lme4::lmer(
  rating_norm ~ stimulus_f + (1 | subjectID),
  regress_data
  )
summary(model)
```
```{r}

hist(regress_data$hunger_1)
```
```{r}
# mean_by_food <- regress_data %>% #filter(health_cond=="unhealthy") %>% 
#   group_by(food_pic) %>% summarise(
#   #hunger=mean(hunger_1,na.rm=TRUE),
#   liking_for_food = mean(liking_rating,na.rm=TRUE),
#   bid=mean(bid,na.rm=TRUE)
#   )
# 
# cor.test(mean_by_food$liking_for_food,mean_by_food$bid)
# 
# 
# 
# plot(mean_by_food$liking_for_food,mean_by_food$bid)
```

```{r}
# mean_by_subject <- regress_data %>% filter(health_cond=="unhealthy" & liking_rating==4) %>% group_by(subject) %>% summarise(
#   hunger=mean(hunger_1,na.rm=TRUE),
#   bid=mean(bid,na.rm=TRUE)
#   )
# 
# cor.test(mean_by_subject$hunger,mean_by_subject$bid)
# 
# 
# 
# plot(mean_by_subject$hunger,mean_by_subject$bid)
```

We don't really care whether or not there are individual-level differences in the interaction between taste ratings and hunger norms. we just want to know, overall, whether they interact and whether modeling that interaction can make the model more predictive.

In fact, individual-level differences in interaction between taste ratings and hunger norms don't make sense. there aren't individual-level differences because there's not an interaction ath the individual-level because there's only one hunger norm per subject. So it's nonsensical to include group-level variables in that bracket.


# Simple model



```{r}

model3a <- lme4::lmer(
  rating_norm ~ run + stimulus_f + hunger_norm + trial_n + (1 | subjectID),
  regress_data[!is.na(regress_data$hunger_norm),]
  )

summary(model3a)

```





Health ratings are the same for every subjectID, so it makes no sense to model the interaction of health_rating and hunger.



```{r}

model3b <- lme4::lmer(
  rating_norm ~ run + stimulus_f*hunger_norm + trial_n + (1 | subjectID),
  regress_data[!is.na(regress_data$hunger_norm),]
  )

summary(model3b)


```


```{r}
anova(model3a,model3b)
```


# With stimulus random effects

If we didn't include random effects of stimulus_f, then this would be significant.

However, it is possible that the effect of the stimulus likeability on ratings differs by subject.

In order to control for this we include it in the random effects of subject.

If we do that we will lose some power to detect interactions of stimulus and hunger.

However, if we don't do this, we will risk labeling some of those individual subject effects on stimulus as effects of stimulus on rating.

But I think we must include random effects of trial.

Possibly this means it is time for some Bayesian mixed effects modeling...


```{r}

model3a <- lme4::lmer(
  rating_norm ~ run + stimulus_f + hunger_norm + trial_n + (1 + stimulus_f | subjectID),
  regress_data[!is.na(regress_data$hunger_norm),]
  )

summary(model3a)

```

Health ratings are the same for every subjectID, so it makes no sense to model the interaction of health_rating and hunger.

```{r}

model3b <- lme4::lmer(
  rating_norm ~ run + stimulus_f*hunger_norm + trial_n + (1 + stimulus_f | subjectID),
  regress_data[!is.na(regress_data$hunger_norm),]
  )

summary(model3b)


```


```{r}
anova(model3a,model3b)
```


That is too bad. The interaction makes sense theoretically. It seems plausible that for "neutral" stimuli, craving ratings would be high but only when the subject is in a very hungry state. This is what we are seeing!

We can demonstrate what the result would be if there really was a strong, subject-level interaction effect between `stimulus_f` and a subject-level variable with some synthetic data. We create a new fake variable, `psy_level`, the subject's level of extrasensory perception (ESP). Then you create a fake interaction of that with the stimulus_f, which necessarily happens at the subject level, and model its causal effect on teh rating norm. Then, control for random effects of the stimulus, butn ot psy level, just as we did with hunger norm. 

We see that unlike the hunger norm model, we don't need to keep stimulus_f out of random effects in order to see a subject-level interaction effect of psyc_level and stimulus_f on the rating. We can also see psy level picking up fake precision (tho not fake point estimates) by omitting stimulus_f from the model.


Also seems to be the way they do it in Applied Multiple Regression/Correlation for the Behavioral Sciences (Cohen, Cohen, West, & Aiken), p551 14.7.2-3.
## Testing with fake dummy data

```{r}

subject_psy_level <- data.frame(
  "subjectID" =unique(regress_data$subjectID), 
  "psy_level" = rnorm(n=unique(regress_data$subjectID))
)
regress_data_synth<-merge(regress_data,subject_psy_level)

#now let's say the subject's psy level interacts with stimulus_f to change ratings
#as well as having a main effect
regress_data_synth$rating_norm<-regress_data_synth$rating_norm+ regress_data_synth$psy_level*as.integer(regress_data_synth$stimulus_f)*0.1


model_fake0 <- lme4::lmer(
  rating_norm ~ run + stimulus_f + psy_level + trial_n + (1 + stimulus_f | subjectID),
  regress_data_synth[!is.na(regress_data_synth$hunger_norm),]
  )

summary(model_fake0)



model_fake1 <- lme4::lmer(
  rating_norm ~ run+stimulus_f*psy_level + trial_n + (1 + stimulus_f | subjectID),
  regress_data_synth[!is.na(regress_data_synth$hunger_norm),]
  )

summary(model_fake1)

anova(model_fake0,model_fake1)


```

Perhaps what we'd need to be absolutely sure is a Bayesian model using rstanarm, but considering the descriptive stats below, I would judge we're not chasing anything substantial.



## Some visualization

## exploratory




```{r}
library(ggplot2)
data_by_subj <- regress_data[!is.na(regress_data$hunger_norm),] %>% 
         group_by(subjectID) %>%
         summarize(
           subj_stimulus_f = mean(as.integer(stimulus_f),na.rm=TRUE),
           #subj_health_rating = mean(as.integer(health_rating),na.rm=TRUE),
           subj_rating_norm=mean(rating_norm,na.rm=TRUE),
           #subj_bid=mean(bid,na.rm=TRUE),
           hunger = mean(hunger_1,na.rm=TRUE)
           )
  
```

```{r}
table(data_by_subj$hunger)
```
OK. Only 14 subjects at hunger level 5. That is not nearly enough subjects to do this analysis on.

Might revisit once we get the wave 2 data but this isn't worth considering.

Make it stacked and then break out hunger vs. not hungry


```{r}

rating_stimulus_by_hunger <- 
  regress_data[!is.na(regress_data$hunger_1) & !is.na(regress_data$rating_i),] %>%
  group_by(hunger_1,rating_i,stimulus_f) %>%
  summarise(value=n()) %>%
  group_by(hunger_1, stimulus_f) %>%
  mutate(total_over_ratings=sum(value)) %>%
  ungroup() %>%
  mutate(prop=value/total_over_ratings) %>%
  mutate(hunger_level=paste0("hunger level = ",hunger_1)) %>%
  data.frame
ggplot(
  rating_stimulus_by_hunger,
  aes(x=stimulus_f,y=prop,group=interaction(hunger_1),fill=rating_i)
)+geom_bar(stat="identity")+facet_wrap(~hunger_level)+
  scale_y_continuous(labels=scales::percent_format())
```


```{r}
ggplot(
  rating_stimulus_by_hunger,
  aes(x=hunger_1,y=prop,group=stimulus_f,fill=rating_i)
)+geom_bar(stat="identity")+facet_wrap(~stimulus_f)+
  scale_y_continuous(labels=scales::percent_format())
```



If we had a simpler subject-average linear model, is it significant?

In a subject average model, each subject had some food that was no crave, neutral, and crave.
some subjects were very hungry, others not so hungry.
We want to know: does the interaction between crave level and hunger change the rating?

```{r}
subject_avg_data<-regress_data[!is.na(regress_data$hunger_numeric) & !is.na(regress_data$rating_i),] %>%
  group_by(subjectID,stimulus_f,hunger_numeric,run) %>%
  summarize(mean_rating=mean(rating_i))

subject_avg_data$run_i<-as.integer(factor(subject_avg_data$run,levels=paste0("run",1:4)))
#including run is cheatinb but only a little bit.

summary(lm(mean_rating~stimulus_f + stimulus_f:hunger_numeric+run_i,subject_avg_data))
```


### copied from SST


OK. Let's plot slopes for liking and bid, by hunger...

```{r}
data_by_subj$hunger_factor <- factor(data_by_subj$hunger)
ggplot(data_by_subj,
       aes(x=subj_rating_norm, y=subj_stimulus_f, group=hunger_factor, color=hunger_factor)
       )+
  geom_smooth(method='lm', formula= y~x)+
  scale_x_continuous(name="subject average crave rating")+
  geom_point()+
  labs(main="subject average crave rating vs. subject average food liking rating: across subjects")
  
```


```{r}
summary(lm(subj_rating_norm~subj_stimulus_f*hunger,
           data_by_subj))

#this is across subjects variance only! 
```


```{r}
regress_data$hunger_numeric<-as.numeric(regress_data$hunger_1)
ggplot(regress_data %>% filter(subjectID %in% names(table(regress_data$subjectID)[1:20])), 
       aes(x=rating_norm, y=stimulus_f,color=hunger_numeric)) +
  geom_smooth(method='lm', formula= y~x) +
  geom_point()+
  #scale_x_continuous(name="subject average bid", labels = scales::dollar_format()) +
  facet_wrap(subjectID~.,nrow = 5)
  

```
```{r}

regress_data$hunger_factor<-as.factor(regress_data$hunger_1)
ggplot(regress_data %>% filter(hunger_1 %in% c(1,5)) %>% filter(subjectID %in% names(table(.$subjectID)[1:100])), 
       aes(x=liking_rating, y=bid,color=hunger_factor,group=subjectID)) +
  geom_line(stat="smooth",method = "lm", formula = y ~ x,
              size = 0.5,
              se=FALSE,
              alpha = 0.5)
  #geom_smooth(method='lm', formula= y~x,se=FALSE,alpha=0.2)
  
#table(regress_data$liking_rating)
```
The slopes show, for each subject, how bids change as a factor of liking. 
