---
title: "WTP Model first pass"
output: html_notebook
---

This is a first-pass attempt to model willingness to pay data. Let's put the code together, WITHOUT testing the data, then consider pre-registration and then a test.

What are we pre-registering? Something like:
 - health and liking scores predict payment scores significantly better than either choice alone
 - hunger ratings moderate liking, so that an interaction term can be observed between liking and hunger when predicting bid, indicating that liking is more important for predicting the bid score when participants are hungrier.
 - hunger ratings also moderate the influence of health, so that an interaction can be observed between liking and hunger when predicting bids so that when participants are hungrier liking is less important

To model these data, we'll use a multi-level model, where we predict individual bid based on health and liking score. At the participant level, we'll model hunger.

Do we model any other participant factors? These might include:

 - obesity level
 - demographics (sex/gender, age, income)
 - PSS

With only ~200 subjects, we're probably under-specified to test _interactions_ with more than a couple of participant-level variables.

Any other subject-level variables that might interact to predict greater predictivity of liking vs. health?

self control
 - impulsivity scale
 - self control scale
 - tempest self regulation scale for eating
 - restraint scale
 
food scarcity
  - childhood financial security
  - adult food security scale

reward sensitivity
 - Food Craving Inventory
 
Food habits
 - Food Frequency Inventory

Before testing each of these we may want to run some sort of correlation on them to look at the correlations between the scales. If items are uncorrelated, we could include them together in a single regression. If they are correlated, we might want to avoid testing them together, test their interaction, or pick one scale over another to analyze.

## Implementation

### First: group-level predictors

In linear modeling terms what we are looking for is a *varying slope*; the varying slope will have a *group-level predictor* (e.g., hunger).

See Gelman & Hill, 12.6: group-level predictors; also 13.1.

### Next: interaction of group-level predictor

this is discussed in 13.1

What we have isn't analogous to the simple radon problem, where we'res predicting indiviual-level (house) radon level from an individual-level predictor (floor=0 or 1) and a group-level (county) predictor. That would be analogous to predicting bid size based on hunger, food health, and food likeability separately. And I think, in a model, this would be using a group predictor to model the intercept of the individual level prediction.

Rather we want to get an interaction of the group-level predictor with the individual-level predictor. In the radon example, this would be like looking for an interaction between floor and county-level radon level.

In a multi-level model this isn't too complicated, right--it's just including the group-level item as a predictor of the group-level variable. This might be descrribed as predicting the slope $\beta_j$.

Gelman _still_ doesn't spell out the form for this in lme4 or lmer, though he does discuss it extensively. So. a quick google...

brief discussion here: https://biologyforfun.wordpress.com/2017/06/19/adding-group-level-predictors-in-glmm-using-lme4/ - not high quality and they specifically caution against using p-values ot test significance. Wonder if Gelman knows how to do it.

Gelman covers this in Section 17.2:  varying intercepts and slopes with group-level predictors. He only offers Bugs code, though. We might use stan.

Can try: https://cran.r-project.org/web/packages/equatiomatic/vignettes/lme4-lmer.html

See also: https://github.com/lme4/lme4/issues/473

hmmm...so, individual-level predictors are food healthiness and tastiness. we might add RT but let's keep it simple for now.


Let's get some data.


```{r}
Sys.setenv(R_CONFIG_ACTIVE = Sys.info()["nodename"])
data_dir <- config::get("dev_analysis_data_dir")
#hunger data
setwd(paste0(paste0(data_dir,"hunger/")))

source("DEV-Session1Data_R_2022-04-19_2347.r")
redcap_data<-data
rm(data)
```

```{r}
Sys.setenv(R_CONFIG_ACTIVE = Sys.info()["nodename"])
data_dir <- config::get("dev_analysis_data_dir")

library(readr)
wtp_raw <- read_csv(paste0(data_dir,"wtp_behavdesign_clean.csv"))

```


```{r}
library(dplyr)
table(redcap_data$hunger_1)
session_1_redcap_data <-redcap_data %>% filter(grepl("session_1", redcap_event_name))
hunger_data <- session_1_redcap_data %>% select(dev_id,hunger_1)

regress_data<-merge(wtp_raw,hunger_data,by.x="subject",by.y="dev_id",all.x = TRUE,all.y=FALSE)
```

Now let's adapt the columns to normed columns with hte names we used in the synthetic dtaset.


```{r}
#regress_data<-regress_data[1:1000,]
regress_data[regress_data$response=="NULL","response"] <- NA
regress_data$response<-as.numeric(regress_data$response)
regress_data <- regress_data%>% group_by(subject,run,wave) %>% mutate(min_response=min(response,na.rm=TRUE),max_response=max(response,na.rm=TRUE)) %>% ungroup()
regress_data$response_range <- regress_data$max_response - regress_data$min_response
stopifnot(max(regress_data$response_range)==3)#max of the max range should be 3 exactly, the range from the max response minus the min response
#there are two groups of responses here grouped by run
#some use range 1,2,3,4; others use range 5,6,7,8
#we need to combine those for value.
value_adjustment <- 0 - 4*(regress_data$min_response>4)
regress_data$value_level <- regress_data$response + value_adjustment
#regress_data$value <- factor(regress_data$value_level,levels = c(1,2,3,4),labels="$0.00","$0.50","$1.00","$1.50")

regress_data[regress_data$liking_rating==0,"liking_rating"]<-NA
table(regress_data$value_level)
```


```{r}

#must have tried for half an hour to et this to work within the loop and it didn't...
standardize<-function(x){return((x-mean(x,na.rm=TRUE))/sd(x,na.rm=TRUE))}

regress_data$bid <- (regress_data$value_level-1)*0.5
regress_data$bid_norm <- standardize(regress_data$bid)

regress_data$health_rating <- factor(regress_data$health_cond)
regress_data$liking_rating_norm <- standardize(regress_data$liking_rating)

regress_data$hunger_norm <- standardize(regress_data$hunger_1)
```

```{r}
library(lme4)

model <- lme4::lmer(
  bid_norm ~ health_rating + liking_rating_norm + (1 | subject),
  regress_data
  )
summary(model)
```
```{r}

hist(regress_data$hunger_1)
```


We don't really care whether or not there are individual-level differences in the interaction between taste ratings and hunger norms. we just want to know, overall, whether they interact and whether modeling that interaction can make the model more predictive.

In fact, individual-level differences in interaction between taste ratings and hunger norms don't make sense. there aren't individual-level differences because there's not an interaction ath the individual-level because there's only one hunger norm per subject. So it's nonsensical to include group-level variables in that bracket.



```{r}
library(lme4)

model1 <- lme4::lmer(
  bid_norm ~ run + health_rating + liking_rating_norm + hunger_norm + (1+ liking_rating_norm + health_rating | subject),
  regress_data
  )
summary(model1)

#coef(model1)
```

That's a non-significant effect for hunger. It is in the reverse direction to what we'd predict. But we weren't interestd in the main effct, particularly. What does it do as an interaction term?


```{r}

model2 <- lme4::lmer(
  bid_norm ~ run + health_rating + liking_rating_norm*hunger_norm + (1+ liking_rating_norm + health_rating | subject),
  regress_data
  )

summary(model2)


```


```{r}

model3 <- lme4::lmer(
  bid_norm ~ run + health_rating*hunger_norm + liking_rating_norm*hunger_norm + (1+ liking_rating_norm + health_rating | subject),
  regress_data
  )

summary(model3)


```


```{r}
anova(model1, model2, model3)
```

Alright. miserable :-(


## Some investigation of a simpler model.

```{r}

model3a <- lme4::lmer(
  bid_norm ~ run + health_rating + liking_rating_norm + (1 | subject),
  regress_data[!is.na(regress_data$hunger_norm),]
  )

summary(model3a)

```

Health ratings are the same for every subject, so it makes no sense to model the interaction of health_rating and hunger.

```{r}

model3b <- lme4::lmer(
  bid_norm ~ run + health_rating + liking_rating_norm*hunger_norm + (1 | subject),
  regress_data[!is.na(regress_data$hunger_norm),]
  )

summary(model3b)


```


```{r}
anova(model3a,model3b)
```


## Some visualization



```{r}
library(ggplot2)
data_by_subj <- regress_data[!is.na(regress_data$hunger_norm),] %>% 
         group_by(subject) %>%
         summarize(
           subj_liking_rating_norm = mean(liking_rating_norm,na.rm=TRUE),
           subj_health_rating = mean(as.integer(health_rating),na.rm=TRUE),
           subj_bid_norm=mean(bid_norm,na.rm=TRUE),
           subj_bid=mean(bid,na.rm=TRUE),
           hunger = mean(hunger_1,na.rm=TRUE)
           )
  
```
OK. Let's plot slopes for liking and bid, by hunger...

```{r}
data_by_subj$hunger_factor <- factor(data_by_subj$hunger)
ggplot(data_by_subj,
       aes(x=subj_bid, y=subj_liking_rating_norm, group=hunger_factor, color=hunger_factor)
       )+
  geom_smooth(method='lm', formula= y~x)+
  scale_x_continuous(name="subject average bid",labels = scales::dollar_format())+
  geom_point()+
  labs(main="subject average bid to subject liking rating: across subjects")
  
```
```{r}
summary(lm(subj_bid_norm~subj_liking_rating_norm*hunger,
           data_by_subj))

#this is across subjects variance only! 
```


```{r}
regress_data$hunger_numeric<-as.numeric(regress_data$hunger_1)
ggplot(regress_data %>% filter(subject %in% names(table(regress_data$subject)[1:20])), 
       aes(x=bid_norm, y=liking_rating_norm,color=hunger_numeric)) +
  geom_smooth(method='lm', formula= y~x) +
  geom_point()+
  #scale_x_continuous(name="subject average bid", labels = scales::dollar_format()) +
  facet_wrap(subject~.,nrow = 5)
  

```
```{r}

regress_data$hunger_factor<-as.factor(regress_data$hunger_1)
ggplot(regress_data %>% filter(hunger_1 %in% c(1,5)) %>% filter(subject %in% names(table(.$subject)[1:100])), 
       aes(x=liking_rating, y=bid,color=hunger_factor,group=subject)) +
  geom_line(stat="smooth",method = "lm", formula = y ~ x,
              size = 0.5,
              se=FALSE,
              alpha = 0.5)
  #geom_smooth(method='lm', formula= y~x,se=FALSE,alpha=0.2)
  
#table(regress_data$liking_rating)
```
The slopes show, for each subject, how bids change as a factor of liking. 
## plotting bid-liking ratio over hunger level

```{r}
regress_data$bid_over_like <- regress_data$bid/regress_data$liking_rating

grouped_regress_data <- regress_data %>% group_by(subject) %>% summarize(
  mean_bid_over_like = mean(bid_over_like,na.rm=TRUE),
  hunger = mean(hunger_1,na.rm=TRUE))

ggplot(grouped_regress_data,aes(x=hunger,y=mean_bid_over_like))+geom_point() +
  geom_smooth(method='lm', formula= y~x,se=FALSE,alpha=0.2)
```


## no liking

```{r}

model_no_liking <- lme4::lmer(
  bid_norm ~ run + health_rating + (1 + health_rating | subject),
  regress_data
  )

summary(model_no_liking)

model_no_health <- lme4::lmer(
  bid_norm ~ run + liking_rating_norm + (1+ liking_rating_norm | subject),
  regress_data
  )

summary(model_no_health)


```

```{r}
model_liking_health <- lme4::lmer(
  bid_norm ~ run + liking_rating_norm +health_rating + (1+ liking_rating_norm +health_rating | subject),
  regress_data
  )

summary(model_liking_health)
```


```{r}
anova(model_liking_health, model_no_health)
```


```{r}
anova(model_liking_health, model_no_liking)
```




